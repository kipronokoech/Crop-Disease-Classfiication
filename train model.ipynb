{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"train model.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qX_SXyVDxuCX","colab_type":"text"},"source":["## Mount the drive. \n","#### This applies to running the code on Google collab."]},{"cell_type":"code","metadata":{"id":"CUSKSRzRxc5Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0f39116e-e32d-4a66-a58f-5e2404ed8413","executionInfo":{"status":"ok","timestamp":1591214580064,"user_tz":-120,"elapsed":808,"user":{"displayName":"Kiprono Elijah Koech","photoUrl":"https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAFC0/5qWxrSvSeJU/s64/photo.jpg","userId":"06588571517751136640"}}},"source":["#Uncomment this to mount file system if you are running on Googl Colab\n","from google.colab import drive\n","drive.mount(\"/content/gdrive/\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pSNsIGw5xChu","colab_type":"text"},"source":["## Load required packages"]},{"cell_type":"code","metadata":{"id":"Gdlu5dc2xChv","colab_type":"code","colab":{}},"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","from keras.preprocessing.image import ImageDataGenerator,img_to_array\n","from keras.optimizers import Adam\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","#from CNN import kcnn_6\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from imutils import paths\n","import numpy as np\n","import random\n","import pickle\n","import cv2 as cv\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","from keras import backend as K\n","from keras.models import save_model,load_model\n","from collections import defaultdict\n","#import tqdm_utils\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgYA2umOyBrw","colab_type":"code","colab":{}},"source":["#Comment this if not running on Colab\n","os.chdir(\"/content/gdrive/My Drive/Crop Disease\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrCzRQdAxCh2","colab_type":"text"},"source":["## Initialize model parameters"]},{"cell_type":"code","metadata":{"id":"Z6BUm0a0xCh3","colab_type":"code","colab":{}},"source":["# initialize the number of epochs to train for, initial learning rate,\n","# batch size, and image dimensions\n","epochs = 5 #using small number of epochs because tje data available data is just for demonstration\n","#Full dataset is here: https://drive.google.com/drive/folders/1en8BwI3kyQFXJZh7R2vmCsp7WV9atpkM?usp=sharing\n","lr = 1e-3 #initial learning rate\n","bs = 32 #batch size\n","image_dims = (224,224 , 3) #Model input shape\n","# initialize the data and labels\n","data = []\n","labels = []\n","# grab the image paths and randomly shuffle them\n","#path to the train folder\n","imagePaths = sorted(list(paths.list_images(\"./train\")))\n","random.seed(42)\n","random.shuffle(imagePaths)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hx94XG4-xCh5","colab_type":"code","colab":{}},"source":["# loop over the input images\n","for imagePath in imagePaths:\n","    \n","    # load the image, pre-process it, and store it in the data list\n","    image = cv.imread(imagePath)\n","    image = cv.resize(image, (image_dims[1], image_dims[0]),cv.INTER_AREA)\n","    image = img_to_array(image)\n","    data.append(image)\n","\n","    # extract the class label from the image path and update the\n","    # labels list\n","    label = imagePath.split(os.path.sep)[-2]\n","\n","    labels.append(label)\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhOmNnmLxCh8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bc7107ce-6691-4446-ff2c-88525186db33","executionInfo":{"status":"ok","timestamp":1591214776576,"user_tz":-120,"elapsed":814,"user":{"displayName":"Kiprono Elijah Koech","photoUrl":"https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAFC0/5qWxrSvSeJU/s64/photo.jpg","userId":"06588571517751136640"}}},"source":["\n","# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","#printing the size of the image data. This value should be less that the RAM size of the\n","#computer otherwise you need to train the model on the generator\n","print(\"[INFO] data matrix: {:.2f}MB\".format(\n","\tdata.nbytes / (1024 * 1000.0)))\n","# binarize the labels\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n","# partition the data into training and testing splits using 80% of\n","# the data for training and the remaining 20% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data,\n","\tlabels, test_size=0.2)#, random_state=42)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[INFO] data matrix: 14.11MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P6u9CVDKxCh-","colab_type":"code","colab":{}},"source":["#remark: save the label binarizer to disk\n","f=open(\"./saved models/weights1.pickle\",\"wb\")\n","f.write(pickle.dumps(lb))\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mOVbZkgxCiA","colab_type":"code","colab":{}},"source":["#defining the base model. Transfer learning of InceptionV3\n","\n","def base_model(use_imagenet=True):\n","    \n","    # load pre-trained model graph, don't add final layer\n","    model = (keras.applications.InceptionV3(include_top=False, input_shape=image_dims,\n","                                            weights='imagenet' if use_imagenet else None))\n","    \n","    # add global pooling just like in InceptionV3\n","    new_output = keras.layers.GlobalAveragePooling2D()(model.output)\n","    \n","    # add new dense layer for our labels\n","    new_output = keras.layers.Dense(len(lb.classes_), activation='softmax')(new_output)\n","    model = keras.engine.training.Model(model.inputs, new_output)\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HsQTvCGxCiD","colab_type":"code","colab":{}},"source":["# initialize the model\n","model = base_model();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xwpdHf8kxCiF","colab_type":"code","colab":{}},"source":["# set all layers trainable by default\n","for layer in model.layers:\n","    layer.trainable = True\n","    if isinstance(layer, keras.layers.BatchNormalization):\n","        # we do aggressive exponential smoothing of batch norm\n","        # parameters to faster adjust to our new dataset\n","        layer.momentum = 0.7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wc4qEZ9sxCiH","colab_type":"code","colab":{}},"source":["# fix deep layers (fine-tuning only last 50)\n","for layer in model.layers[:-50]:\n","    # fix all but batch norm layers, because we need to update moving averages for a new dataset!\n","    if not isinstance(layer, keras.layers.BatchNormalization):\n","        layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSGoBn2zxCiJ","colab_type":"code","colab":{}},"source":["#Define model checkpoints\n","filepath=\"./saved models/saved-model-{epoch:02d}-{val_loss:.2f}.hdf5\"\n","#filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n","mc =  ModelCheckpoint(filepath,monitor=\"val_loss\",verbose=1,save_best_only=True,mode=\"min\")\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=9)\n","callbacks_list=[mc,es]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubw8hiRlxCiM","colab_type":"code","colab":{}},"source":["#remark: compile new model\n","model.compile(\n","    loss='categorical_crossentropy',  # we train 102-way classification\n","    optimizer=keras.optimizers.adamax(lr=1e-3),  # we can take big lr here because we fixed first layers\n","    metrics=[\"accuracy\",\"mse\"]  # report accuracy during training\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4hkbzQWzFpP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":418},"outputId":"b42df063-d7fe-4f39-d925-6915b9ac09b1","executionInfo":{"status":"ok","timestamp":1591215004139,"user_tz":-120,"elapsed":68716,"user":{"displayName":"Kiprono Elijah Koech","photoUrl":"https://lh5.googleusercontent.com/-1cfglh_j7Tw/AAAAAAAAAAI/AAAAAAAAFC0/5qWxrSvSeJU/s64/photo.jpg","userId":"06588571517751136640"}}},"source":["#[INFO] training network...\"\n","H = model.fit(\n","\ttrainX, trainY, batch_size=bs,\n","\tvalidation_data=(testX, testY),\n","\tepochs=epochs, verbose=1,callbacks=callbacks_list)#,steps_per_epoch=len(trainX) // BS"],"execution_count":32,"outputs":[{"output_type":"stream","text":["[INFO] training network...\n","Train on 9 samples, validate on 3 samples\n","Epoch 1/5\n","9/9 [==============================] - 19s 2s/step - loss: 1.3328 - accuracy: 0.3333 - mse: 0.2633 - val_loss: 0.3587 - val_accuracy: 1.0000 - val_mse: 0.0597\n","\n","Epoch 00001: val_loss improved from inf to 0.35875, saving model to ./saved models/saved-model-01-0.36.hdf5\n","Epoch 2/5\n","9/9 [==============================] - 4s 396ms/step - loss: 4.6526e-04 - accuracy: 1.0000 - mse: 2.2514e-07 - val_loss: 0.2907 - val_accuracy: 1.0000 - val_mse: 0.0530\n","\n","Epoch 00002: val_loss improved from 0.35875 to 0.29071, saving model to ./saved models/saved-model-02-0.29.hdf5\n","Epoch 3/5\n","9/9 [==============================] - 4s 399ms/step - loss: 1.2604e-04 - accuracy: 1.0000 - mse: 1.8944e-08 - val_loss: 0.2745 - val_accuracy: 1.0000 - val_mse: 0.0524\n","\n","Epoch 00003: val_loss improved from 0.29071 to 0.27450, saving model to ./saved models/saved-model-03-0.27.hdf5\n","Epoch 4/5\n","9/9 [==============================] - 6s 676ms/step - loss: 6.9997e-05 - accuracy: 1.0000 - mse: 6.5872e-09 - val_loss: 0.2645 - val_accuracy: 1.0000 - val_mse: 0.0516\n","\n","Epoch 00004: val_loss improved from 0.27450 to 0.26446, saving model to ./saved models/saved-model-04-0.26.hdf5\n","Epoch 5/5\n","9/9 [==============================] - 4s 395ms/step - loss: 4.9270e-05 - accuracy: 1.0000 - mse: 3.5888e-09 - val_loss: 0.2575 - val_accuracy: 1.0000 - val_mse: 0.0510\n","\n","Epoch 00005: val_loss improved from 0.26446 to 0.25754, saving model to ./saved models/saved-model-05-0.26.hdf5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sqUfT4MTzLlO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}